{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Forecasting Covid-19 Cases with LSTM"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preparation"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\nsub_df=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pull out state of North Carolina \nnc_train_df=train_df[train_df[\"Province_State\"]==\"North Carolina\"]\nnc_test_df=test_df[test_df[\"Province_State\"]==\"North Carolina\"]\n\n# pull out state of NY\nny_train_df=train_df[train_df[\"Province_State\"]==\"New York\"]\nny_test_df=test_df[test_df[\"Province_State\"]==\"New York\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nc_train_df.shape,ny_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ny_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nc_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add a data column for days\nnc_train_df[\"days\"]=[x for x in range(1,83)]\nny_train_df[\"days\"]=[x for x in range(1,83)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nc_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ny_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remake dataframe into 2 columns w/ just our days and cases\nnc_train_df=nc_train_df.loc[:,[\"ConfirmedCases\",\"days\"]]\nnc_train_df.set_index('days',inplace=True)\n\nny_train_df=ny_train_df.loc[:,[\"ConfirmedCases\",\"days\"]]\nny_train_df.set_index('days',inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ny_train_df.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 5))\n\nplt.plot(nc_train_df.index,nc_train_df['ConfirmedCases'], c = 'deeppink',label=\"North Carolina\")\nplt.plot(ny_train_df.index,ny_train_df['ConfirmedCases'], c = 'orangered',label=\"New York\")\n\nplt.xlabel(\"\\nDAYS\\n\", fontsize=10)\nplt.ylabel(\"\\nCASES\\n\", fontsize=10)\nplt.title(\"Covid-19 Cases \\n\", fontsize=18)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's load the required libs.\n# We'll be using the Tensorflow backend (default).\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import LSTM\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalize data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef normalize_data(train_df):\n    # get data values from the pandas data frame.\n    values = train_df.values.astype(\"float32\")\n    # apply the MinMax scaler from sklearn\n    scaler = MinMaxScaler(feature_range = (0, 1))\n    dataset = scaler.fit_transform(values)\n    # save normalized dataset into df\n    series = pd.DataFrame(dataset)\n    \n    return dataset,series;\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_nc,series_nc=normalize_data(nc_train_df)\ndataset_ny,series_ny=normalize_data(ny_train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(dataset,TRAIN_SIZE=0.90):\n    #dataset= shuffle(dataset)\n\n    # Shuffle training data.\n    train_size = int(len(dataset) * TRAIN_SIZE)\n    test_size = len(dataset) - train_size\n    train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n    print(\"(training set, test set): \" + str((len(train), len(test))))\n\n    return train,test;\n\ntrain_nc,test_nc=prepare_data(dataset_nc,0.90)\ntrain_ny,test_ny=prepare_data(dataset_ny,0.90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef create_dataset(dataset, window_size = 1):\n    data_X, data_Y = [], []\n    for i in range(len(dataset) - window_size - 1):\n        a = dataset[i:(i + window_size), 0]\n        data_X.append(a)\n        data_Y.append(dataset[i + window_size, 0])\n    return(np.array(data_X), np.array(data_Y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create test and training sets for one-step-ahead regression.\ndef make_one_step_regr_sets(train, test, window_size=1):\n    window_size = 1\n    train_X, train_Y = create_dataset(train, window_size)\n    test_X, test_Y = create_dataset(test, window_size)\n    print(\"Original training data shape:\")\n    print(train_X.shape)\n\n    # Reshape the input data into appropriate form for Keras.\n    train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n    test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n    print(\"New training data shape:\")\n    print(train_X.shape)\n    return train_X, train_Y, test_X, test_Y;\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nc_train_X, nc_train_Y, nc_test_X, nc_test_Y=make_one_step_regr_sets(train_nc, test_nc, window_size=1)\n\nny_train_X, ny_train_Y, ny_test_X, ny_test_Y=make_one_step_regr_sets(train_ny, test_ny, window_size=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Simple LSTM Network"},{"metadata":{},"cell_type":"markdown","source":"* 1 input layer  \n* 1 LSTM layer w/ 4 blocks  \n* 1 Dense layer to produce a single output\n* MSE loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model(train_X, train_Y, window_size = 1):\n    model = Sequential()\n    \n    model.add(LSTM(4, \n                   input_shape = (1, window_size)))\n    model.add(Dense(1))\n    model.compile(loss = \"mean_squared_error\", \n                  optimizer = \"adam\")\n    model.fit(train_X, \n              train_Y, \n              epochs = 100, \n              batch_size = 1)\n    model.summary()\n    return(model)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the first model.\nnc_model = fit_model(nc_train_X, nc_train_Y, window_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the first model.\nny_model = fit_model(ny_train_X, ny_train_Y, window_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n\ndef predict_and_score(model, X, Y):\n    # Make predictions on the original scale of the data.\n    pred = scaler.inverse_transform(model.predict(X))\n    # Prepare Y data to also be on the original scale for interpretability.\n    orig_data = scaler.inverse_transform([Y])\n    # Calculate RMSE.\n    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n    return(score, pred, orig_data)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nc_rmse_train, nc_train_predict,nc_train_orig = predict_and_score(nc_model, nc_train_X,nc_train_Y)\nnc_rmse_test, nc_test_predict, nc_test_orig = predict_and_score(nc_model, nc_test_X, nc_test_Y)\n\nprint(\"Training data score: %.2f RMSE\" % nc_rmse_train)\nprint(\"Test data score: %.2f RMSE\" % nc_rmse_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ny_rmse_train, ny_train_predict,ny_train_orig = predict_and_score(ny_model, ny_train_X,ny_train_Y)\nny_rmse_test, ny_test_predict, ny_test_orig = predict_and_score(ny_model, ny_test_X, ny_test_Y)\n\nprint(\"Training data score: %.2f RMSE\" % ny_rmse_train)\nprint(\"Test data score: %.2f RMSE\" % ny_rmse_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_predictions(dataset, train_predict, test_predict,title=\"Covid-19 Cases\"):\n    # Start with training predictions.\n    train_predict_plot = np.empty_like(dataset)\n    train_predict_plot[:, :] = np.nan\n    train_predict_plot[window_size:len(train_predict) + window_size, :] = train_predict\n\n    # Add test predictions.\n    test_predict_plot = np.empty_like(dataset)\n    test_predict_plot[:, :] = np.nan\n    test_predict_plot[len(train_predict) + (window_size * 2) + 1:len(dataset) - 1, :] = test_predict\n\n    sns.set_context('poster')\n    # Create the plot.\n    plt.figure(figsize = (15, 5))\n    plt.plot(scaler.inverse_transform(dataset), label = \"True value\", color='dimgrey')\n    plt.plot(train_predict_plot, label = \"Training set prediction\",color='mediumpurple')\n    plt.plot(test_predict_plot, label = \"Test set prediction\",color='chartreuse')\n    plt.xlabel(\"Days\")\n    plt.ylabel(\"Number of Cases\")\n    plt.title(\"{} \\n\".format(title))\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_predictions(dataset_nc, nc_train_predict, nc_test_predict,title=\"NC Covid-19 Cases\")\nplot_predictions(dataset_ny, ny_train_predict, ny_test_predict,title=\"NY Covid-19 Cases\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(model.history.history.keys())\nnc_losses_lstm =nc_model.history.history['loss']\nny_losses_lstm =ny_model.history.history['loss']\n\nplt.figure(figsize=(12,4))\nplt.xticks(np.arange(0,120,10))\nplt.plot(range(len(losses_lstm)),nc_losses_lstm, c=\"deeppink\", label=\"nc\")\nplt.plot(range(len(losses_lstm)),ny_losses_lstm, c=\"orangered\", label=\"ny\")\nplt.title(\"Loss\\n\")\nplt.legend();\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bidirectional Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(lr=0.001)\n# define model\nbi_model = Sequential()\nbi_model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(1, 1)))\nbi_model.add(Dense(1))\nbi_model.compile(optimizer=opt, loss='mse')\nbi_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"nc_bi_model_history = bi_model.fit(nc_train_X, nc_train_Y, epochs=600, batch_size=256, validation_data=(nc_test_X, nc_test_Y),\n                    verbose=0, shuffle=False,callbacks=[EarlyStopping(patience=10)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ny_bi_model_history = bi_model.fit(ny_train_X, ny_train_Y, epochs=600, batch_size=256, validation_data=(ny_test_X, ny_test_Y),\n                    verbose=0, shuffle=False,callbacks=[EarlyStopping(patience=10)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_and_score(model, X, Y):\n    # Make predictions on the original scale of the data.\n    pred = scaler.inverse_transform(model.predict(X))\n    # Prepare Y data to also be on the original scale for interpretability.\n    orig_data = scaler.inverse_transform([Y])\n    # Calculate RMSE.\n    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n    return score, pred;\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ny_bi_rmse_train, ny_bi_train_predict = predict_and_score(bi_model, ny_train_X, ny_train_Y)\nny_bi_rmse_test, ny_bi_test_predict = predict_and_score(bi_model, ny_test_X, ny_test_Y)\nnc_bi_rmse_train, nc_bi_train_predict = predict_and_score(bi_model, nc_train_X, nc_train_Y)\nnc_bi_rmse_test, nc_bi_test_predict = predict_and_score(bi_model, nc_test_X, nc_test_Y)\n\nprint('NY Predictions:')\nprint(\"Training data score: %.2f RMSE\" % ny_bi_rmse_train)\nprint(\"Test data score: %.2f RMSE\" % ny_bi_rmse_test)\nprint('\\nNC Predictions:')\n\nprint(\"Training data score: %.2f RMSE\" % nc_bi_rmse_train)\nprint(\"Test data score: %.2f RMSE\" % nc_bi_rmse_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_predictions(dataset_ny, ny_bi_train_predict, ny_bi_test_predict,title=\"NY Covid-19 Cases \\nbidirectional LSTM\")\nplot_predictions(dataset_nc, nc_bi_train_predict, nc_bi_test_predict,title=\"NC Covid-19 Cases \\nbidirectional LSTM\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(model.history.history.keys())\nnc_losses_lstm =nc_model.history.history['loss']\nny_losses_lstm =ny_model.history.history['loss']\n\nplt.figure(figsize=(12,4))\nplt.xticks(np.arange(0,120,10))\nplt.plot(range(len(losses_lstm)),nc_losses_lstm, c=\"deeppink\", label=\"nc\")\nplt.plot(range(len(losses_lstm)),ny_losses_lstm, c=\"orangered\", label=\"ny\")\nplt.title(\"Bidirectional LSTM Loss\\n\")\nplt.legend();\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pylab import rcParams\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Activation, Dropout, Bidirectional, GRU\nfrom keras.optimizers import SGD, Adadelta, RMSprop, Adam, Nadam\nfrom keras.regularizers import l1_l2\nfrom keras.callbacks import EarlyStopping\nfrom tqdm import tqdm\n\n\nreg = l1_l2(l1=0.0015, l2=0.0)\nopt = Adam(lr=0.0015)\n\nbi_model = Sequential()\nbi_model.add(Bidirectional(LSTM(140, activation='relu', return_sequences=True, kernel_regularizer=reg, recurrent_regularizer=reg)))\nbi_model.add(Bidirectional(LSTM(140, activation='relu', return_sequences=True, kernel_regularizer=reg, recurrent_regularizer=reg)))\nbi_model.add(Bidirectional(LSTM(140, activation='relu', kernel_regularizer=reg, recurrent_regularizer=reg)))\nbi_model.add(Dense(28))\nbi_model.add(Dense(1))\nbi_model.add(Activation('linear'))\nbi_model.compile(loss='mean_absolute_error', optimizer=opt)\n\nbi_model_history = bi_model.fit(nc_train_X, nc_train_Y, epochs=600, batch_size=256, validation_data=(test_X, test_Y),\n                    verbose=0, shuffle=False,callbacks=[EarlyStopping(patience=10)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/ternaryrealm/lstm-time-series-explorations-with-keras"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}